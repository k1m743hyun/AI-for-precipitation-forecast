{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"convolution 시각화","provenance":[],"collapsed_sections":["_SrdhZeZcqXO"],"mount_file_id":"1ZQEetlmxtZMDqDNA9spRDYgxaHrY7fw6","authorship_tag":"ABX9TyPTMB+NRmFTNFBKE4gCm2NA"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"O7HX2cshbrvH","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('drive/My Drive/Colab Notebooks/Project/AIFrenz_Season2')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZjOsUMLyb3ML","colab_type":"code","outputId":"ffcc6861-3211-4513-da18-948f115f09c9","executionInfo":{"status":"ok","timestamp":1590487385908,"user_tz":-540,"elapsed":1046,"user":{"displayName":"조준형","photoUrl":"","userId":"07026978245339768740"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pwd"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Colab Notebooks/Project/AIFrenz_Season2'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"Ou8Bxn42b4Lv","colab_type":"code","outputId":"a31137b7-4933-4c2a-dffe-4ff619b2c147","executionInfo":{"status":"ok","timestamp":1590487396124,"user_tz":-540,"elapsed":792,"user":{"displayName":"조준형","photoUrl":"","userId":"07026978245339768740"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 1.x"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cHXFA6dyb6vf","colab_type":"code","outputId":"2a53bded-5f62-47d3-943c-d6df0b7844d1","executionInfo":{"status":"ok","timestamp":1590487845500,"user_tz":-540,"elapsed":885,"user":{"displayName":"조준형","photoUrl":"","userId":"07026978245339768740"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import *\n","from keras import backend as K\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from sklearn.model_selection import train_test_split , KFold"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WBdffcc4cIFZ","colab_type":"code","colab":{}},"source":["np.random.seed(777)\n","tf.set_random_seed(777)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-xwDSsbXcJ-V","colab_type":"code","colab":{}},"source":["# Load test_images\n","path = './data/dataset/' \n","test_image = np.load(path+'test_images.npy')\n","test_image.shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n9nXpU3bcfYC","colab_type":"text"},"source":["# 평가지표"]},{"cell_type":"code","metadata":{"id":"ytF41tFBcfIx","colab_type":"code","colab":{}},"source":["from sklearn.metrics import f1_score\n","\n","def mae(y_true, y_pred) :\n","    \n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    \n","    y_true = y_true.reshape(1, -1)[0]\n","    \n","    y_pred = y_pred.reshape(1, -1)[0]\n","    \n","    over_threshold = y_true >= 0.1\n","    \n","    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n","\n","def fscore(y_true, y_pred):\n","    \n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    \n","    y_true = y_true.reshape(1, -1)[0]\n","    \n","    y_pred = y_pred.reshape(1, -1)[0]\n","    \n","    remove_NAs = y_true >= 0\n","    \n","    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n","    \n","    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n","    \n","    return(f1_score(y_true, y_pred))\n","\n","def maeOverFscore(y_true, y_pred):\n","    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)\n","\n","def fscore_keras(y_true, y_pred):\n","    score = tf.py_function(func=fscore, inp=[y_true, y_pred], Tout=tf.float32, name='fscore_keras')\n","    return score\n","\n","def maeOverFscore_keras(y_true, y_pred):\n","    score = tf.py_function(func=maeOverFscore, inp=[y_true, y_pred], Tout=tf.float32,  name='custom_mse') \n","    return score\n","\n","def mae_over_fscore(y_true, y_pred):\n","    '''\n","    y_true: sample_submission.csv 형태의 실제 값\n","    y_pred: sample_submission.csv 형태의 예측 값\n","    '''\n","\n","    y_true = np.array(y_true)\n","    y_true = y_true.reshape(1, -1)[0]  \n","    \n","    y_pred = np.array(y_pred)\n","    y_pred = y_pred.reshape(1, -1)[0]\n","    \n","    # 실제값이 0.1 이상인 픽셀의 위치 확인\n","    IsGreaterThanEqualTo_PointOne = y_true >= 0.1\n","    \n","    # 실제 값에 결측값이 없는 픽셀의 위치 확인 \n","    IsNotMissing = y_true >= 0\n","    \n","    # mae 계산\n","    mae = np.mean(np.abs(y_true[IsGreaterThanEqualTo_PointOne] - y_pred[IsGreaterThanEqualTo_PointOne]))\n","    \n","    # f1_score 계산 위해, 실제값에 결측값이 없는 픽셀에 대해 1과 0으로 값 변환\n","    y_true = np.where(y_true[IsNotMissing] >= 0.1, 1, 0)\n","    \n","    y_pred = np.where(y_pred[IsNotMissing] >= 0.1, 1, 0)\n","    \n","    # f1_score 계산    \n","    f_score = f1_score(y_true, y_pred) \n","    \n","    # f1_score가 0일 나올 경우를 대비하여 소량의 값 (1e-07) 추가 \n","    return mae / (f_score + 1e-07) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zVM93ZqDfgqf","colab_type":"text"},"source":["# 시각화"]},{"cell_type":"code","metadata":{"id":"zgjz1rgKfjTV","colab_type":"code","colab":{}},"source":["num_layer = len(model.layers)\n","print('# of Layers:',num_layer)\n","for layer in model.layers:\n","    print(layer.name)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D1OUr9AdcOq_","colab_type":"text"},"source":["# 각 Layer feature map 시각화"]},{"cell_type":"code","metadata":{"id":"sjKsjAiJcd5p","colab_type":"code","colab":{}},"source":["model = load_model('U_Net_200520_ver_1_1.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IU4s_644cYUw","colab_type":"code","colab":{}},"source":["def show_conv_layer(test_data,test_idx,num_layer):\n","    # 데이터 전처리\n","    img = test_data[test_idx,:,:,:9]\n","    img_tensor = np.expand_dims(img,axis=0)\n","    plt.matshow(img_tensor[test_idx,:,:,5]) # 5: 시각화 할 이미지의 채널\n","    plt.show()\n","\n","    # 입력 텐서와 출력 텐서의 리스트로 모델 객체 만들기\n","    layer_outputs = [layer.output for layer in model.layers[:num_layer]][1:]\n","    activation_model = Model(inputs=model.input, outputs=layer_outputs)\n","\n","    # 예측 모드로 모델 실행\n","    activations = activation_model.predict(img_tensor)\n","\n","    # 각 layer명 추출\n","    layer_names = []\n","    for layer in model.layers[:num_layer]:\n","        layer_names.append(layer.name)\n","\n","    images_per_row = 16 # 1 row에 들어갈 이미지 수 \n","\n","    # 이미지 삽입 그리드 초기화\n","    for layer_name , layer_activation in zip(layer_names,activations):\n","        n_features = layer_activation.shape[-1]\n","        size = layer_activation.shape[1]\n","        n_cols = n_features // images_per_row\n","        display_grid = np.zeros((size*n_cols,images_per_row*size))\n","\n","        for col in range(n_cols):\n","            for row in range(images_per_row):\n","                channel_image = layer_activation[0,:,:,col*images_per_row + row]\n","                channel_image -= channel_image.mean()\n","                channel_image /= channel_image.std()\n","                channel_image *= 64\n","                channel_image += 128\n","                channel_image = np.clip(channel_image,0,255).astype('uint8')\n","                display_grid[col*size:(col+1)*size,row*size:(row+1)*size] = channel_image\n","\n","        scale = 1. / size\n","        plt.figure(figsize=(scale*display_grid.shape[1] , scale*display_grid.shape[0]))\n","        plt.title(layer_name)\n","        plt.grid(False)\n","        plt.imshow(display_grid,aspect='auto',cmap='viridis')\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IUPY6zFecbJt","colab_type":"code","colab":{}},"source":["num_layer = len(model.layers)\n","test_idx = np.random.randint(2416)\n","show_conv_layer(test_image,test_idx,num_layer)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_SrdhZeZcqXO","colab_type":"text"},"source":["### 개별 모듈"]},{"cell_type":"code","metadata":{"id":"rViKS1nZcr_p","colab_type":"code","colab":{}},"source":["# 개별 이미지 전처리\n","img = test_image[10,:,:,:9]\n","img_tensor = np.expand_dims(img,axis=0)\n","print(img_tensor.shape)\n","plt.matshow(img_tensor[0,:,:,5])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7YTECzpfcuD1","colab_type":"code","colab":{}},"source":["# 입력 텐서와 출력 텐서의 리스트로 모델 객체 만들기\n","layer_outputs = [layer.output for layer in model.layers[:15]][1:]\n","activation_model = Model(inputs=model.input, outputs=layer_outputs)\n","\n","# 예측 모드로 모델 실행\n","activations = activation_model.predict(img_tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h6dAcpy9cuAH","colab_type":"code","colab":{}},"source":["# 첫번째 합성곱층의 활성값\n","first_layer_activation = activations[0]\n","print(first_layer_activation.shape)\n","# 20번째 채널 시각화\n","plt.matshow(first_layer_activation[0,:,:,1],cmap='viridis')\n","# 16번째 채널 시각화\n","plt.matshow(first_layer_activation[0,:,:,2],cmap='viridis')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ViSC2Yhct59","colab_type":"code","colab":{}},"source":["# 중간층의 모든 활성화 채널 시각화\n","layer_names = []\n","for layer in model.layers[:39]:\n","    layer_names.append(layer.name)\n","\n","images_per_row = 16\n","\n","for layer_name , layer_activation in zip(layer_names,activations):\n","    n_features = layer_activation.shape[-1]\n","    size = layer_activation.shape[1]\n","    print(size)\n","    n_cols = n_features // images_per_row\n","    display_grid = np.zeros((size*n_cols,images_per_row*size))\n","\n","    for col in range(n_cols):\n","        for row in range(images_per_row):\n","            channel_image = layer_activation[0,:,:,col*images_per_row + row]\n","            channel_image -= channel_image.mean()\n","            channel_image /= channel_image.std()\n","            channel_image *= 64\n","            channel_image += 128\n","            channel_image = np.clip(channel_image,0,255).astype('uint8')\n","            display_grid[col*size:(col+1)*size,row*size:(row+1)*size] = channel_image\n","\n","    scale = 1. / size\n","    print(scale)\n","    plt.figure(figsize=(scale*display_grid.shape[1],scale*display_grid.shape[0]))\n","    plt.title(layer_name)\n","    plt.grid(False)\n","    plt.imshow(display_grid,aspect='auto',cmap='viridis')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0FJT-bAYc6YB","colab_type":"text"},"source":["# 필터 시각화\n","\n","필터가 반응하는 시각적 패턴을 그림\n","\n","특정 conv layer의 한 필터 값을 최대화하는 손실함수를 정의하여 확률적 경사 상승법 적용."]},{"cell_type":"code","metadata":{"id":"I2pVf2Hlc3c8","colab_type":"code","colab":{}},"source":["# 필터 시각화를 위한 손실 함수 정의\n","layer_name = 'conv2d_21'\n","filter_index = 0\n","\n","layer_output = model.get_layer(layer_name).output\n","loss = K.mean(layer_output[:,:,:,filter_index])\n","\n","# 입력에 대한 손실의 그래디언트 구하기\n","gradient = K.gradient(loss,model.input)[0]\n","gradient /= (K.sqrt(K.mean(K.square(gradient))) + 1e-5) #정규화\n","\n","# 입력값에 대한 넘파이 출력값 추출\n","iterate = K.function([model.input],[loss,gradient])\n","loss_value , gradient_value = iterate([np.zeros((1,40,40,9))])\n","\n","# 확률적 경사상승법을 사용한 손실 최대화\n","input_img_data = np.random.random((1,40,40,9))*20 + 128.\n","step = 1.\n","for i in ragne(40):\n","    loss_value , gradient_value = iterate([input_img_data])\n","\n","    input_img_data += gradient_value * step"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFOF-pOdct2f","colab_type":"code","colab":{}},"source":["# 텐서를 이미지로 형태로 변환하는 함수\n","def deprocess_image(x):\n","    x -= x.mean()\n","    x /= (x.std() + 1e-5)\n","    x *= 0.1\n","\n","    x += 0.5\n","    x = np.clip(x,0,1)\n","\n","    x *= 255\n","    x = np.clip(x,0,255).astype('uint8')\n","    return x\n","\n","# 필터 시각화 이미지를 만드는 함수\n","def generate_pattern(layer_name,filter_index,size=150):\n","    layer_output = model.get_layer(layer_name).output\n","    loss = K.mean(layer_output[:,:,:,filter_index])\n","\n","    gradient = K.gradient(loss,model.input)[0]\n","    gradient /= (K.sqrt(K.mean(K.square(gradient))) + 1e-5)\n","\n","    iterate = K.function([model.input],[loss,gradient])\n","\n","    input_img_data = np.random.random((1,size,size,3)) * 20 + 128. # 잡음 섞인 gray scale로 시작\n","\n","    step = 1.\n","    for i in ragne(40):\n","        loss_value , gradient_value = iterate([input_img_data])\n","        input_img_data += gradient_value * step\n","\n","    img = input_img_data[0]\n","    return deprocess_image(img)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSsCR9wNdHFu","colab_type":"code","colab":{}},"source":["# 층에 있는 각 필터에 반응하는 패턴 생성\n","layer_name = 'block1_conv1'\n","size = 64\n","margin = 5\n","\n","results = np.zeros((8*szie + 7*margin, 8*size + 7*margin, 3), dtype='uint8')\n","\n","for i in range(8):\n","    for j in range(8):\n","        filter_img = generate_pattern(layer_name, i + (j*8),size=size)\n","        horizontal_start = i * size + i * margin\n","        horizontal_end = horizontal_start + size\n","        vertical_start = j * size + j*margin\n","        vertical_end = vertical_start + size\n","\n","        results[horizontal_start:horizontal_end,vertical_start,vertical_end,:] = filter_img\n","\n","plt.figure(figsize=(20,20))\n","plt.imshow(results)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bEwHgvzjdLF9","colab_type":"text"},"source":["# 클래스 활성화 히트맵"]},{"cell_type":"code","metadata":{"id":"RM-r26OodNxD","colab_type":"code","colab":{}},"source":["from keras.preprocessing import image\n","# 모델에 입력하기 위한 전처리\n","img_path = 'data'\n","\n","img = image.load_img(img_path,target_size=(224,224))\n","\n","x = image.img_to_array(img)\n","x = np.expand_dims(x,axis=0)\n","x = preprocess_input(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fzpHpBt8dSTk","colab_type":"code","colab":{}},"source":["pred = model.predict(x)\n","print('prediced:',decode_predictions(pred,top=3)[0])\n","np.argmax(pred[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Otw_fCQdSRD","colab_type":"code","colab":{}},"source":["# Grad_CAM 알고리즘 \n","africa_elephant_output = model.output[:,386]\n","\n","last_conv_layer = model.get_layer('block5_conv3') # 마지막 합성곱층의 특성 맵\n","gradient = K.gradients(africa_elephant_output,last_conv_layer)[0] # 마지막 특성 맵 출력에 대한 코끼리클래스의 그래디언트\n","pooled_gradient = K.mean(gradient,axis=(0,1,2)) # 특성 맵 채널별 그래디언트 평균이 담긴 (512,) 크기의 벡터\n","\n","iterate = K.function([model.input],[pooled_gradient,last_conv_layer.output[0]])\n","\n","pooled_gradient_value , conv_layer_output_value = iterate([x])\n","\n","for i in rage(512):\n","    conv_layer_output_value[:,:,i] *= pooled_gradient_value[i]\n","\n","heatmap = np.mean(conv_layer_output_value,axis=1)\n","\n","heatmap = np.maximum(heatmap,0)\n","heatmap /= np.max(heatmap)\n","plt.matshow(heatmap)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7RYiuB4gdSOy","colab_type":"code","colab":{}},"source":["# 원본 이미지에 히트맵 덧붙이기\n","import cv2\n","\n","img = cv2.imread(img_path)\n","\n","heatmap = cv2.resize(heatmap,(img.shape[1],img.shape[0]))\n","\n","heatmap = np.uint8(255*heatmap)\n","\n","heatmap = cv2.applyColorMap(heatmap,cv2.COLORMAP_JET)\n","\n","superimposed_img = heatmap * 0.4 + img\n","\n","cv2.imwrite('저장경로',superimposed_img)"],"execution_count":0,"outputs":[]}]}